{
  "fileName": "report.py",
  "filePath": "metrics/report.py",
  "url": "/blob/master/metrics/report.py",
  "summary": "```mermaid\nflowchart TD\n    A[Start] --> B{Load Evaluation Logs}\n    B --> C{Load Gold Results}\n    C --> D{Calculate Metrics}\n    D --> E{Generate Report}\n    E --> F{Generate Summary}\n    F --> G[End]\n\n    subgraph get_eval_report\n        D -->|Fail to Pass| F2P[Calculate F2P Metrics]\n        D -->|Pass to Pass| P2P[Calculate P2P Metrics]\n        D -->|Fail to Fail| F2F[Calculate F2F Metrics]\n        D -->|Pass to Fail| P2F[Calculate P2F Metrics]\n    end\n\n    subgraph get_eval_reports_for_logs\n        B -->|For Each Log| C\n        C -->|Find Corresponding Gold Result| D\n        D -->|For Each Test Case| E\n    end\n\n    subgraph get_eval_reports_for_dir\n        A -->|Load Logs from Directory| B\n    end\n\n    subgraph get_model_eval_summary\n        A -->|Load Predictions| preds[Load Predictions]\n        preds -->|Filter by Repo| filter[Filter Predictions]\n        filter -->|Get Reports| get_eval_reports_for_dir\n        get_eval_reports_for_dir -->|Compile Summary| F\n    end\n\n    subgraph get_model_report\n        A -->|Load Predictions| predictions[Load Predictions]\n        predictions -->|For Each Prediction| check[Check Model Patch]\n        check -->|Exists| exists[Model Patch Exists]\n        exists -->|Log Exists| log_exists[Log File Exists]\n        log_exists -->|Eval Log Found| found[Eval Log Found]\n        found -->|Generate Report| get_eval_report\n        get_eval_report -->|Resolution Status| resolution[Check Resolution Status]\n        resolution -->|Compile Report| G\n    end\n```\nThis mermaid diagram illustrates the flow and functionalities of the provided code snippets, focusing on the evaluation report generation, model evaluation summary, and model report generation processes within the larger project context.",
  "questions": "",
  "checksum": "be46ea96abee610f82989e3b51ccfde4"
}